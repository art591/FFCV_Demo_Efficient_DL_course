{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f459c303",
   "metadata": {},
   "source": [
    "# FFCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26543f90",
   "metadata": {},
   "source": [
    "## Simple Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38bc34b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feacef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffcv\n",
    "from ffcv.writer import DatasetWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c412b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class OttoDataset:\n",
    "    def __init__(self,):\n",
    "        self.X = np.load('../data/otto_ll/X_num_train.npy')\n",
    "        self.y = np.load('../data/otto_ll/y_train.npy')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.X[idx].astype('float32'), self.y[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "\n",
    "dataset = OttoDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f33510c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 4., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 2., 0., 0., 4., 0., 0., 0., 2., 0., 0., 0., 4., 0.,\n",
       "        0., 2., 0., 0., 0., 0., 3., 2., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
       "        0., 4., 1., 0., 0., 0., 0., 0., 0., 0., 3., 0., 0., 1., 1., 2., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        2., 0., 0., 0., 0., 0., 3., 0.], dtype=float32),\n",
       " 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e71d9e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BytesField',\n",
       " 'Field',\n",
       " 'FloatField',\n",
       " 'IntField',\n",
       " 'JSONField',\n",
       " 'NDArrayField',\n",
       " 'RGBImageField',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'base',\n",
       " 'basics',\n",
       " 'bytes',\n",
       " 'decoders',\n",
       " 'json',\n",
       " 'ndarray',\n",
       " 'rgb_image']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(ffcv.fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e91a4db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39601/39601 [00:00<00:00, 394486.72it/s]\n"
     ]
    }
   ],
   "source": [
    "from ffcv.fields import NDArrayField, IntField\n",
    "from ffcv.loader import Loader, OrderOption\n",
    "\n",
    "writer = DatasetWriter('my_easy_data.beton', {\n",
    "    'x': NDArrayField(shape=(93,), dtype=np.dtype('float32')),\n",
    "    'y': IntField(),\n",
    "\n",
    "}, num_workers=16)\n",
    "\n",
    "writer.from_indexed_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea1e7141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ffcv.loader import Loader, OrderOption\n",
    "\n",
    "ffcv_loader = Loader('my_easy_data.beton',\n",
    "                batch_size=1024,\n",
    "                num_workers=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4635e4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "torch_loader = DataLoader(dataset, batch_size=1024, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29ca36ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class MySuperPooperNetwork(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(nn.Linear(in_features, 256), nn.ReLU(),\n",
    "                              nn.Linear(256, 256), nn.ReLU(),\n",
    "                              nn.Linear(256, out_features))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1090cf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MySuperPooperNetwork(93, 9).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 5e-4)\n",
    "critetion =  nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "022e80d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 57.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 879.14it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 1066.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 964.65it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 1048.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 967.43it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 914.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 986.71it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 1006.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 978.59it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "ffcv_time = []\n",
    "\n",
    "for j in range(10):\n",
    "    for i, b in enumerate(tqdm(ffcv_loader)):\n",
    "        x, y = b\n",
    "        x = x.cuda()\n",
    "        y = y.cuda().flatten()\n",
    "        loss = critetion(model(x), y)\n",
    "        torch.cuda.synchronize()\n",
    "        if i > 10:\n",
    "            ffcv_time.append(time.time() - now)\n",
    "        now = time.time()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3aafc610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 53.03it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 51.84it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 50.65it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 50.19it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 50.42it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 50.62it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 50.39it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 49.81it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 49.31it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 51.86it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch_time = []\n",
    "\n",
    "for j in range(10):\n",
    "    for i, b in enumerate(tqdm(torch_loader)):\n",
    "        x, y = b\n",
    "        x = x.cuda()\n",
    "        y = y.cuda().flatten()\n",
    "        loss = critetion(model(x), y)\n",
    "        torch.cuda.synchronize()\n",
    "        if i > 10:\n",
    "            torch_time.append(time.time() - now)\n",
    "        now = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3b728bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>0.95-Quantile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FFCV</th>\n",
       "      <td>0.000952</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.001160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TORCH</th>\n",
       "      <td>0.010384</td>\n",
       "      <td>0.010803</td>\n",
       "      <td>0.014767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UPLIFT (%)</th>\n",
       "      <td>-90.832665</td>\n",
       "      <td>-91.143333</td>\n",
       "      <td>-92.144388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Mean     Median  0.95-Quantile\n",
       "FFCV         0.000952   0.000957       0.001160\n",
       "TORCH        0.010384   0.010803       0.014767\n",
       "UPLIFT (%) -90.832665 -91.143333     -92.144388"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "means = []\n",
    "medians = []\n",
    "quantiles = []\n",
    "names = []\n",
    "\n",
    "for name, times in zip(['FFCV', 'TORCH'], [ffcv_time, torch_time]):\n",
    "    means.append(np.mean(times))\n",
    "    medians.append(np.median(times))\n",
    "    quantiles.append(np.quantile(times, 0.95))\n",
    "    names.append(name)\n",
    "    \n",
    "d = pd.DataFrame({\"Mean\": means, \"Median\": medians, \"0.95-Quantile\": quantiles})\n",
    "d.index = names\n",
    "up = ((d.loc['FFCV'] - d.loc['TORCH']) / d.loc['TORCH']) * 100\n",
    "d.loc['UPLIFT (%)'] = up.values\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760645e5",
   "metadata": {},
   "source": [
    "Отлично! В данном случае из-за большого батча и маленькой сетки мы получили идеальный кейс использования FFCV с ботлнеком в даталоудинге."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f5d394",
   "metadata": {},
   "source": [
    "# Кефир-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d2712b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class WideBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super(WideBlock, self).__init__()\n",
    "        self.block_layer = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, stride=stride, padding=1)\n",
    "        )\n",
    "        self.use_residual = stride != 1 or in_channels != out_channels\n",
    "        res_conv_layer = []\n",
    "        if self.use_residual:\n",
    "            res_conv_layer.append(nn.Sequential(nn.Conv2d(in_channels, out_channels, 1, stride=stride)))\n",
    "        self.res_conv = nn.Sequential(*res_conv_layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block_layer(x)\n",
    "        out += self.res_conv(x)\n",
    "        return out\n",
    "\n",
    "class WideResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_blocks, init_stride):\n",
    "        super(WideResidualBlock, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(num_blocks):\n",
    "            if i == 0:\n",
    "                layers.append(WideBlock(in_channels, out_channels, init_stride))\n",
    "            else:\n",
    "                layers.append(WideBlock(out_channels, out_channels, 1))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "class MyWideResNet28_10(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MyWideResNet28_10, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1),\n",
    "            WideResidualBlock(16, 160, 4, 1),\n",
    "            WideResidualBlock(160, 320, 4, 2),\n",
    "            WideResidualBlock(320, 640, 4, 2),\n",
    "            nn.BatchNorm2d(640, momentum=0.9),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(8)\n",
    "        )\n",
    "        self.linear = nn.Linear(640, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return self.linear(x.view(x.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a45ae98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10('/tmp', train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f64d8791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=32x32 at 0x7F9CF71D5E80>, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d07774d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [00:00<00:00, 496850.66it/s]\n"
     ]
    }
   ],
   "source": [
    "from ffcv.fields import RGBImageField, IntField\n",
    "\n",
    "\n",
    "cifar_writer = DatasetWriter('cifar.beton', {\n",
    "        'image': RGBImageField(),\n",
    "        'label': IntField()\n",
    "    },\n",
    ")\n",
    "cifar_writer.from_indexed_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6b2ba92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Convert',\n",
       " 'Cutout',\n",
       " 'ImageMixup',\n",
       " 'LabelMixup',\n",
       " 'MixupToOneHot',\n",
       " 'ModuleWrapper',\n",
       " 'NormalizeImage',\n",
       " 'Poison',\n",
       " 'RandomHorizontalFlip',\n",
       " 'RandomResizedCrop',\n",
       " 'RandomTranslate',\n",
       " 'ReplaceLabel',\n",
       " 'Squeeze',\n",
       " 'ToDevice',\n",
       " 'ToTensor',\n",
       " 'ToTorchImage',\n",
       " 'View',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'common',\n",
       " 'cutout',\n",
       " 'flip',\n",
       " 'mixup',\n",
       " 'module',\n",
       " 'normalize',\n",
       " 'ops',\n",
       " 'poisoning',\n",
       " 'random_resized_crop',\n",
       " 'replace_label',\n",
       " 'translate',\n",
       " 'utils']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(ffcv.transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16fca52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ffcv.fields.decoders import IntDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d764670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffcv_loader = Loader('cifar.beton',\n",
    "    batch_size=128,\n",
    "    num_workers=1,\n",
    "    order=OrderOption.QUASI_RANDOM,\n",
    "    pipelines = {\n",
    "        'image': [ffcv.fields.decoders.CenterCropRGBImageDecoder((32, 32), 2/3),\n",
    "                  ffcv.transforms.ToTensor(),\n",
    "                  ffcv.transforms.ToDevice('cuda', non_blocking=True),\n",
    "                  ffcv.transforms.ToTorchImage(),],\n",
    "        'label': [ffcv.fields.decoders.IntDecoder(),\n",
    "                  ffcv.transforms.ToTensor(),\n",
    "                  ffcv.transforms.ToDevice('cuda', non_blocking=True),\n",
    "                  ffcv.transforms.Squeeze()]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2739fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "torch_loader = DataLoader(torchvision.datasets.CIFAR10('/tmp',\n",
    "                                                       transform=torchvision.transforms.Compose(\n",
    "                                                           [\n",
    "                                                           torchvision.transforms.ToTensor(),\n",
    "                                                           torchvision.transforms.Resize((48, 48)),\n",
    "                                                           torchvision.transforms.CenterCrop((32, 32))\n",
    "                                                           ]\n",
    "                                                       ),train=True), \n",
    "                          batch_size=128, num_workers=1, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3ccc5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyWideResNet28_10(10).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-2)\n",
    "critetion =  nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78c64e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:12<00:00, 32.14it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "ffcv_time = []\n",
    "\n",
    "\n",
    "for i, b in enumerate(tqdm(ffcv_loader)):\n",
    "    x, y = b\n",
    "    x = (x / 255)\n",
    "    loss = critetion(model(x), y)\n",
    "    torch.cuda.synchronize()\n",
    "    if i > 10:\n",
    "        ffcv_time.append(time.time() - now)\n",
    "    now = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f898d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:00<00:00, 1048.43it/s]\n"
     ]
    }
   ],
   "source": [
    "ffcv_time_load_only = []\n",
    "\n",
    "for i, b in enumerate(tqdm(ffcv_loader)):\n",
    "    torch.cuda.synchronize()\n",
    "    if i > 10:\n",
    "        ffcv_time_load_only.append(time.time() - now)\n",
    "    now = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5611fd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:11<00:00, 33.57it/s]\n"
     ]
    }
   ],
   "source": [
    "torch_time_load_only = []\n",
    "\n",
    "for i, b in enumerate(tqdm(torch_loader)):\n",
    "    torch.cuda.synchronize()\n",
    "    if i > 10:\n",
    "        torch_time_load_only.append(time.time() - now)\n",
    "    now = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59c1e1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:11<00:00, 33.34it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch_time = []\n",
    "\n",
    "\n",
    "for i, b in enumerate(tqdm(torch_loader)):\n",
    "    x, y = b\n",
    "    x = x.cuda()\n",
    "    y = y.cuda().flatten()\n",
    "    loss = critetion(model(x), y)\n",
    "    torch.cuda.synchronize()\n",
    "    if i > 10:\n",
    "        torch_time.append(time.time() - now)\n",
    "    now = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a13dcff",
   "metadata": {},
   "source": [
    "Full forward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b179a7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>0.95-Quantile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FFCV</th>\n",
       "      <td>0.025751</td>\n",
       "      <td>0.025428</td>\n",
       "      <td>0.027036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TORCH</th>\n",
       "      <td>0.029059</td>\n",
       "      <td>0.029022</td>\n",
       "      <td>0.030230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UPLIFT (%)</th>\n",
       "      <td>-11.383726</td>\n",
       "      <td>-12.383448</td>\n",
       "      <td>-10.563970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Mean     Median  0.95-Quantile\n",
       "FFCV         0.025751   0.025428       0.027036\n",
       "TORCH        0.029059   0.029022       0.030230\n",
       "UPLIFT (%) -11.383726 -12.383448     -10.563970"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "means = []\n",
    "medians = []\n",
    "quantiles = []\n",
    "names = []\n",
    "\n",
    "for name, times in zip(['FFCV', 'TORCH'], [ffcv_time, torch_time]):\n",
    "    means.append(np.mean(times))\n",
    "    medians.append(np.median(times))\n",
    "    quantiles.append(np.quantile(times, 0.95))\n",
    "    names.append(name)\n",
    "    \n",
    "d = pd.DataFrame({\"Mean\": means, \"Median\": medians, \"0.95-Quantile\": quantiles})\n",
    "d.index = names\n",
    "up = ((d.loc['FFCV'] - d.loc['TORCH']) / d.loc['TORCH']) * 100\n",
    "d.loc['UPLIFT (%)'] = up.values\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a387a34",
   "metadata": {},
   "source": [
    "Just dataloader step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7489e3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>0.95-Quantile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FFCV</th>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TORCH</th>\n",
       "      <td>0.028923</td>\n",
       "      <td>0.028822</td>\n",
       "      <td>0.030172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UPLIFT (%)</th>\n",
       "      <td>-97.182661</td>\n",
       "      <td>-97.223900</td>\n",
       "      <td>-97.045736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Mean     Median  0.95-Quantile\n",
       "FFCV         0.000815   0.000800       0.000891\n",
       "TORCH        0.028923   0.028822       0.030172\n",
       "UPLIFT (%) -97.182661 -97.223900     -97.045736"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "means = []\n",
    "medians = []\n",
    "quantiles = []\n",
    "names = []\n",
    "\n",
    "for name, times in zip(['FFCV', 'TORCH'], [ffcv_time_load_only, torch_time_load_only]):\n",
    "    means.append(np.mean(times))\n",
    "    medians.append(np.median(times))\n",
    "    quantiles.append(np.quantile(times, 0.95))\n",
    "    names.append(name)\n",
    "    \n",
    "d = pd.DataFrame({\"Mean\": means, \"Median\": medians, \"0.95-Quantile\": quantiles})\n",
    "d.index = names\n",
    "up = ((d.loc['FFCV'] - d.loc['TORCH']) / d.loc['TORCH']) * 100\n",
    "d.loc['UPLIFT (%)'] = up.values\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5d7ae5",
   "metadata": {},
   "source": [
    "Мы получили, что очень сильно ускоряемся на этапе датлоудинга, но в рамках полного форвард степа разница не такая заметная. В чем причина? Дело в том, что моделька теперь уже не такая маленькая и в случае торчового даталоадера имеет сопоставимое с ним время форвард паса, а это значит что, после того, как CPU положила все свои инструкции для форварда модели на GPU планировщик, то оно может спокойно идти считать тяжелый батч, пока модель будет пыхтеть на GPU. А значит два тяжелых времени по сути пересекаются, а не суммируются."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
